{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOwsuGQQY9OL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRnDnCW-Z7qv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soPGVheskaQP"
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJtwVB2NbOAP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "66\n",
      "8\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['in'])\n",
    "print(tokenizer.word_index['the'])\n",
    "print(tokenizer.word_index['town'])\n",
    "print(tokenizer.word_index['of'])\n",
    "print(tokenizer.word_index['athy'])\n",
    "print(tokenizer.word_index['one'])\n",
    "print(tokenizer.word_index['jeremy'])\n",
    "print(tokenizer.word_index['lanigan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49Cv68JOakwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  4  2 66  8 67 68 69]\n"
     ]
    }
   ],
   "source": [
    "print(xs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iY-jwvfgbEF8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtzlUMYadhKt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  4  2 66  8 67 68]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[5])\n",
    "print(ys[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4myRpB1c4Gg"
   },
   "outputs": [],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9vH8Y59ajYL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples\n",
      "Epoch 1/500\n",
      "453/453 [==============================] - 3s 6ms/sample - loss: 5.5683 - accuracy: 0.0132\n",
      "Epoch 2/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 5.5404 - accuracy: 0.0353\n",
      "Epoch 3/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 5.4742 - accuracy: 0.0508\n",
      "Epoch 4/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 5.2928 - accuracy: 0.0486\n",
      "Epoch 5/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 5.1284 - accuracy: 0.0486\n",
      "Epoch 6/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 5.0682 - accuracy: 0.0486\n",
      "Epoch 7/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 5.0286 - accuracy: 0.0618\n",
      "Epoch 8/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 4.9984 - accuracy: 0.0508\n",
      "Epoch 9/500\n",
      "453/453 [==============================] - 0s 310us/sample - loss: 4.9686 - accuracy: 0.0508\n",
      "Epoch 10/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 4.9215 - accuracy: 0.0486\n",
      "Epoch 11/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 4.8806 - accuracy: 0.0640\n",
      "Epoch 12/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 4.8302 - accuracy: 0.0530\n",
      "Epoch 13/500\n",
      "453/453 [==============================] - 0s 260us/sample - loss: 4.7767 - accuracy: 0.0552\n",
      "Epoch 14/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 4.7246 - accuracy: 0.0662\n",
      "Epoch 15/500\n",
      "453/453 [==============================] - 0s 266us/sample - loss: 4.6773 - accuracy: 0.0574\n",
      "Epoch 16/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 4.6306 - accuracy: 0.0596\n",
      "Epoch 17/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 4.5888 - accuracy: 0.0728\n",
      "Epoch 18/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 4.5529 - accuracy: 0.0861\n",
      "Epoch 19/500\n",
      "453/453 [==============================] - 0s 212us/sample - loss: 4.5172 - accuracy: 0.0861\n",
      "Epoch 20/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 4.4811 - accuracy: 0.0839\n",
      "Epoch 21/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 4.4529 - accuracy: 0.0927\n",
      "Epoch 22/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 4.4176 - accuracy: 0.0905\n",
      "Epoch 23/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 4.3923 - accuracy: 0.0883\n",
      "Epoch 24/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 4.3589 - accuracy: 0.0883\n",
      "Epoch 25/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 4.3293 - accuracy: 0.0949\n",
      "Epoch 26/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 4.2933 - accuracy: 0.1015\n",
      "Epoch 27/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 4.2520 - accuracy: 0.1214\n",
      "Epoch 28/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 4.2292 - accuracy: 0.1104\n",
      "Epoch 29/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 4.1881 - accuracy: 0.1170\n",
      "Epoch 30/500\n",
      "453/453 [==============================] - 0s 280us/sample - loss: 4.1512 - accuracy: 0.1280\n",
      "Epoch 31/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 4.1206 - accuracy: 0.1280\n",
      "Epoch 32/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 4.0884 - accuracy: 0.1258\n",
      "Epoch 33/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 4.0595 - accuracy: 0.1391\n",
      "Epoch 34/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 4.0219 - accuracy: 0.1369\n",
      "Epoch 35/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 3.9888 - accuracy: 0.1413\n",
      "Epoch 36/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 3.9607 - accuracy: 0.1479\n",
      "Epoch 37/500\n",
      "453/453 [==============================] - 0s 260us/sample - loss: 3.9261 - accuracy: 0.1634\n",
      "Epoch 38/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 3.8978 - accuracy: 0.1611\n",
      "Epoch 39/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 3.8631 - accuracy: 0.1611\n",
      "Epoch 40/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 3.8376 - accuracy: 0.1766\n",
      "Epoch 41/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 3.7980 - accuracy: 0.1634\n",
      "Epoch 42/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 3.7516 - accuracy: 0.1744\n",
      "Epoch 43/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 3.7154 - accuracy: 0.1854\n",
      "Epoch 44/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 3.6841 - accuracy: 0.1943\n",
      "Epoch 45/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 3.6436 - accuracy: 0.1987\n",
      "Epoch 46/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 3.6199 - accuracy: 0.2053\n",
      "Epoch 47/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 3.5696 - accuracy: 0.2097\n",
      "Epoch 48/500\n",
      "453/453 [==============================] - 0s 296us/sample - loss: 3.5389 - accuracy: 0.2208\n",
      "Epoch 49/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 3.4998 - accuracy: 0.2185\n",
      "Epoch 50/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 3.4681 - accuracy: 0.2230\n",
      "Epoch 51/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 3.4323 - accuracy: 0.2318\n",
      "Epoch 52/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 3.4027 - accuracy: 0.2318\n",
      "Epoch 53/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 3.3791 - accuracy: 0.2406\n",
      "Epoch 54/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 3.3466 - accuracy: 0.2517\n",
      "Epoch 55/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 3.3024 - accuracy: 0.2627\n",
      "Epoch 56/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 3.2715 - accuracy: 0.2649\n",
      "Epoch 57/500\n",
      "453/453 [==============================] - 0s 212us/sample - loss: 3.2484 - accuracy: 0.2649\n",
      "Epoch 58/500\n",
      "453/453 [==============================] - 0s 202us/sample - loss: 3.2146 - accuracy: 0.2781\n",
      "Epoch 59/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 3.1815 - accuracy: 0.2914\n",
      "Epoch 60/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 3.1492 - accuracy: 0.3068\n",
      "Epoch 61/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 3.1117 - accuracy: 0.3046\n",
      "Epoch 62/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 3.0806 - accuracy: 0.3333\n",
      "Epoch 63/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 3.0569 - accuracy: 0.3311\n",
      "Epoch 64/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 3.0274 - accuracy: 0.3532\n",
      "Epoch 65/500\n",
      "453/453 [==============================] - 0s 288us/sample - loss: 3.0028 - accuracy: 0.3532\n",
      "Epoch 66/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 2.9748 - accuracy: 0.3687\n",
      "Epoch 67/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 2.9536 - accuracy: 0.3576\n",
      "Epoch 68/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 2.9130 - accuracy: 0.3841\n",
      "Epoch 69/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 2.8839 - accuracy: 0.3863\n",
      "Epoch 70/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 2.8592 - accuracy: 0.3974\n",
      "Epoch 71/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 2.8308 - accuracy: 0.3951\n",
      "Epoch 72/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 2.7989 - accuracy: 0.4216\n",
      "Epoch 73/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 2.7734 - accuracy: 0.4216\n",
      "Epoch 74/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 2.7533 - accuracy: 0.4459\n",
      "Epoch 75/500\n",
      "453/453 [==============================] - 0s 198us/sample - loss: 2.7269 - accuracy: 0.4371\n",
      "Epoch 76/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 2.7075 - accuracy: 0.4415\n",
      "Epoch 77/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 2.6755 - accuracy: 0.4592\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 227us/sample - loss: 2.6511 - accuracy: 0.4812\n",
      "Epoch 79/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 2.6204 - accuracy: 0.4879\n",
      "Epoch 80/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 2.5996 - accuracy: 0.4812\n",
      "Epoch 81/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 2.5844 - accuracy: 0.4702\n",
      "Epoch 82/500\n",
      "453/453 [==============================] - 0s 287us/sample - loss: 2.5567 - accuracy: 0.4834\n",
      "Epoch 83/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 2.5340 - accuracy: 0.4834\n",
      "Epoch 84/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 2.4973 - accuracy: 0.4923\n",
      "Epoch 85/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 2.4721 - accuracy: 0.5055\n",
      "Epoch 86/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 2.4561 - accuracy: 0.5033\n",
      "Epoch 87/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 2.4270 - accuracy: 0.5121\n",
      "Epoch 88/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 2.4014 - accuracy: 0.5364\n",
      "Epoch 89/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 2.3763 - accuracy: 0.5386\n",
      "Epoch 90/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 2.3419 - accuracy: 0.5585\n",
      "Epoch 91/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 2.3368 - accuracy: 0.5408\n",
      "Epoch 92/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 2.3426 - accuracy: 0.5408\n",
      "Epoch 93/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 2.3408 - accuracy: 0.5453\n",
      "Epoch 94/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 2.2978 - accuracy: 0.5651\n",
      "Epoch 95/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 2.2740 - accuracy: 0.5695\n",
      "Epoch 96/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 2.2381 - accuracy: 0.5872\n",
      "Epoch 97/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 2.2048 - accuracy: 0.6026\n",
      "Epoch 98/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 2.1823 - accuracy: 0.5960\n",
      "Epoch 99/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 2.1705 - accuracy: 0.6004\n",
      "Epoch 100/500\n",
      "453/453 [==============================] - 0s 293us/sample - loss: 2.1412 - accuracy: 0.6071\n",
      "Epoch 101/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 2.1111 - accuracy: 0.6159\n",
      "Epoch 102/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 2.0848 - accuracy: 0.6336\n",
      "Epoch 103/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 2.0593 - accuracy: 0.6313\n",
      "Epoch 104/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 2.0383 - accuracy: 0.6358\n",
      "Epoch 105/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 2.0163 - accuracy: 0.6424\n",
      "Epoch 106/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 1.9944 - accuracy: 0.6556\n",
      "Epoch 107/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 1.9821 - accuracy: 0.6534\n",
      "Epoch 108/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 1.9583 - accuracy: 0.6623\n",
      "Epoch 109/500\n",
      "453/453 [==============================] - 0s 211us/sample - loss: 1.9362 - accuracy: 0.6600\n",
      "Epoch 110/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 1.9172 - accuracy: 0.6755\n",
      "Epoch 111/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 1.8951 - accuracy: 0.6711\n",
      "Epoch 112/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 1.8764 - accuracy: 0.6667\n",
      "Epoch 113/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 1.8571 - accuracy: 0.6799\n",
      "Epoch 114/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 1.8342 - accuracy: 0.6821\n",
      "Epoch 115/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 1.8138 - accuracy: 0.6865\n",
      "Epoch 116/500\n",
      "453/453 [==============================] - 0s 209us/sample - loss: 1.7970 - accuracy: 0.6976\n",
      "Epoch 117/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 1.7774 - accuracy: 0.6998\n",
      "Epoch 118/500\n",
      "453/453 [==============================] - 0s 268us/sample - loss: 1.7615 - accuracy: 0.6976\n",
      "Epoch 119/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 1.7616 - accuracy: 0.6998\n",
      "Epoch 120/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 1.7447 - accuracy: 0.6821\n",
      "Epoch 121/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 1.7244 - accuracy: 0.6998\n",
      "Epoch 122/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 1.7051 - accuracy: 0.7020\n",
      "Epoch 123/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 1.6791 - accuracy: 0.7196\n",
      "Epoch 124/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 1.6605 - accuracy: 0.7108\n",
      "Epoch 125/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 1.6427 - accuracy: 0.7219\n",
      "Epoch 126/500\n",
      "453/453 [==============================] - 0s 201us/sample - loss: 1.6618 - accuracy: 0.7086\n",
      "Epoch 127/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 1.6341 - accuracy: 0.7174\n",
      "Epoch 128/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 1.6000 - accuracy: 0.7263\n",
      "Epoch 129/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 1.5789 - accuracy: 0.7395\n",
      "Epoch 130/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 1.5641 - accuracy: 0.7439\n",
      "Epoch 131/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 1.5407 - accuracy: 0.7550\n",
      "Epoch 132/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 1.5245 - accuracy: 0.7616\n",
      "Epoch 133/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 1.5082 - accuracy: 0.7748\n",
      "Epoch 134/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 1.5029 - accuracy: 0.7616\n",
      "Epoch 135/500\n",
      "453/453 [==============================] - 0s 289us/sample - loss: 1.4817 - accuracy: 0.7726\n",
      "Epoch 136/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 1.4667 - accuracy: 0.7815\n",
      "Epoch 137/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 1.4498 - accuracy: 0.7815\n",
      "Epoch 138/500\n",
      "453/453 [==============================] - 0s 268us/sample - loss: 1.4372 - accuracy: 0.7770\n",
      "Epoch 139/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 1.4186 - accuracy: 0.7815\n",
      "Epoch 140/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 1.4043 - accuracy: 0.7837\n",
      "Epoch 141/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 1.3862 - accuracy: 0.7925\n",
      "Epoch 142/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 1.3703 - accuracy: 0.7903\n",
      "Epoch 143/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 1.3558 - accuracy: 0.8013\n",
      "Epoch 144/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 1.3594 - accuracy: 0.7947\n",
      "Epoch 145/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 1.3432 - accuracy: 0.7947\n",
      "Epoch 146/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 1.3338 - accuracy: 0.8035\n",
      "Epoch 147/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 1.3163 - accuracy: 0.8057\n",
      "Epoch 148/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 1.2997 - accuracy: 0.8057\n",
      "Epoch 149/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 1.2842 - accuracy: 0.8102\n",
      "Epoch 150/500\n",
      "453/453 [==============================] - 0s 287us/sample - loss: 1.2772 - accuracy: 0.8102\n",
      "Epoch 151/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 1.2738 - accuracy: 0.8035\n",
      "Epoch 152/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 1.2607 - accuracy: 0.8013\n",
      "Epoch 153/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 1.2516 - accuracy: 0.8168\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 249us/sample - loss: 1.2505 - accuracy: 0.8168\n",
      "Epoch 155/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 1.2671 - accuracy: 0.8057\n",
      "Epoch 156/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 1.2306 - accuracy: 0.8234\n",
      "Epoch 157/500\n",
      "453/453 [==============================] - 0s 189us/sample - loss: 1.2114 - accuracy: 0.8278\n",
      "Epoch 158/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 1.1981 - accuracy: 0.8256\n",
      "Epoch 159/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 1.1624 - accuracy: 0.8433\n",
      "Epoch 160/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 1.1706 - accuracy: 0.8344\n",
      "Epoch 161/500\n",
      "453/453 [==============================] - 0s 212us/sample - loss: 1.1755 - accuracy: 0.8322\n",
      "Epoch 162/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 1.1589 - accuracy: 0.8389\n",
      "Epoch 163/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 1.1354 - accuracy: 0.8411\n",
      "Epoch 164/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 1.1201 - accuracy: 0.8389\n",
      "Epoch 165/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 1.1046 - accuracy: 0.8521\n",
      "Epoch 166/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 1.0843 - accuracy: 0.8521\n",
      "Epoch 167/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 1.0659 - accuracy: 0.8543\n",
      "Epoch 168/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 1.0511 - accuracy: 0.8565\n",
      "Epoch 169/500\n",
      "453/453 [==============================] - 0s 310us/sample - loss: 1.0378 - accuracy: 0.8609\n",
      "Epoch 170/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 1.0275 - accuracy: 0.8587\n",
      "Epoch 171/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 1.0134 - accuracy: 0.8653\n",
      "Epoch 172/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 1.0026 - accuracy: 0.8631\n",
      "Epoch 173/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 0.9917 - accuracy: 0.8698\n",
      "Epoch 174/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.9835 - accuracy: 0.8786\n",
      "Epoch 175/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.9736 - accuracy: 0.8786\n",
      "Epoch 176/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.9643 - accuracy: 0.8764\n",
      "Epoch 177/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.9599 - accuracy: 0.8742\n",
      "Epoch 178/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.9466 - accuracy: 0.8698\n",
      "Epoch 179/500\n",
      "453/453 [==============================] - 0s 202us/sample - loss: 0.9352 - accuracy: 0.8786\n",
      "Epoch 180/500\n",
      "453/453 [==============================] - 0s 209us/sample - loss: 0.9245 - accuracy: 0.8764\n",
      "Epoch 181/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 0.9150 - accuracy: 0.8808\n",
      "Epoch 182/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.9042 - accuracy: 0.8874\n",
      "Epoch 183/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 0.8968 - accuracy: 0.8874\n",
      "Epoch 184/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.8874 - accuracy: 0.8918\n",
      "Epoch 185/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 0.9411 - accuracy: 0.8609\n",
      "Epoch 186/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.9254 - accuracy: 0.8587\n",
      "Epoch 187/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.8867 - accuracy: 0.8852\n",
      "Epoch 188/500\n",
      "453/453 [==============================] - 0s 287us/sample - loss: 0.8716 - accuracy: 0.8940\n",
      "Epoch 189/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.8601 - accuracy: 0.8962\n",
      "Epoch 190/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.8605 - accuracy: 0.8896\n",
      "Epoch 191/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.8453 - accuracy: 0.8896\n",
      "Epoch 192/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.8336 - accuracy: 0.8940\n",
      "Epoch 193/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.8247 - accuracy: 0.8896\n",
      "Epoch 194/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.8208 - accuracy: 0.8896\n",
      "Epoch 195/500\n",
      "453/453 [==============================] - 0s 210us/sample - loss: 0.8032 - accuracy: 0.8962\n",
      "Epoch 196/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.7974 - accuracy: 0.8896\n",
      "Epoch 197/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.7804 - accuracy: 0.8962\n",
      "Epoch 198/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.7700 - accuracy: 0.9007\n",
      "Epoch 199/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.7628 - accuracy: 0.9051\n",
      "Epoch 200/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.7525 - accuracy: 0.9007\n",
      "Epoch 201/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.7560 - accuracy: 0.9007\n",
      "Epoch 202/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 0.7479 - accuracy: 0.9007\n",
      "Epoch 203/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 0.7424 - accuracy: 0.9007\n",
      "Epoch 204/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.7314 - accuracy: 0.9051\n",
      "Epoch 205/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 0.7198 - accuracy: 0.9095\n",
      "Epoch 206/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 0.7028 - accuracy: 0.9095\n",
      "Epoch 207/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 0.6910 - accuracy: 0.9117\n",
      "Epoch 208/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.6821 - accuracy: 0.9205\n",
      "Epoch 209/500\n",
      "453/453 [==============================] - 0s 309us/sample - loss: 0.6757 - accuracy: 0.9205\n",
      "Epoch 210/500\n",
      "453/453 [==============================] - 0s 212us/sample - loss: 0.6673 - accuracy: 0.9183\n",
      "Epoch 211/500\n",
      "453/453 [==============================] - 0s 203us/sample - loss: 0.6647 - accuracy: 0.9117\n",
      "Epoch 212/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 0.6561 - accuracy: 0.9161\n",
      "Epoch 213/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.6476 - accuracy: 0.9139\n",
      "Epoch 214/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.6380 - accuracy: 0.9183\n",
      "Epoch 215/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.6317 - accuracy: 0.9205\n",
      "Epoch 216/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.6246 - accuracy: 0.9205\n",
      "Epoch 217/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.6153 - accuracy: 0.9249\n",
      "Epoch 218/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.6088 - accuracy: 0.9227\n",
      "Epoch 219/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.6024 - accuracy: 0.9294\n",
      "Epoch 220/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.6027 - accuracy: 0.9249\n",
      "Epoch 221/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.5970 - accuracy: 0.9227\n",
      "Epoch 222/500\n",
      "453/453 [==============================] - 0s 208us/sample - loss: 0.5960 - accuracy: 0.9227\n",
      "Epoch 223/500\n",
      "453/453 [==============================] - 0s 197us/sample - loss: 0.5781 - accuracy: 0.9272\n",
      "Epoch 224/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 0.5703 - accuracy: 0.9272\n",
      "Epoch 225/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.5626 - accuracy: 0.9316\n",
      "Epoch 226/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.5574 - accuracy: 0.9316\n",
      "Epoch 227/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.5506 - accuracy: 0.9338\n",
      "Epoch 228/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 0.5466 - accuracy: 0.9338\n",
      "Epoch 229/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.5390 - accuracy: 0.9294\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 227us/sample - loss: 0.5336 - accuracy: 0.9316\n",
      "Epoch 231/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.5276 - accuracy: 0.9338\n",
      "Epoch 232/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.5221 - accuracy: 0.9338\n",
      "Epoch 233/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.5171 - accuracy: 0.9360\n",
      "Epoch 234/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.5118 - accuracy: 0.9338\n",
      "Epoch 235/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.5073 - accuracy: 0.9338\n",
      "Epoch 236/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.5014 - accuracy: 0.9360\n",
      "Epoch 237/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.4964 - accuracy: 0.9360\n",
      "Epoch 238/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.4917 - accuracy: 0.9404\n",
      "Epoch 239/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.4878 - accuracy: 0.9382\n",
      "Epoch 240/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.4835 - accuracy: 0.9382\n",
      "Epoch 241/500\n",
      "453/453 [==============================] - 0s 212us/sample - loss: 0.4801 - accuracy: 0.9382\n",
      "Epoch 242/500\n",
      "453/453 [==============================] - 0s 209us/sample - loss: 0.4742 - accuracy: 0.9426\n",
      "Epoch 243/500\n",
      "453/453 [==============================] - 0s 219us/sample - loss: 0.4701 - accuracy: 0.9404\n",
      "Epoch 244/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.4667 - accuracy: 0.9404\n",
      "Epoch 245/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.4634 - accuracy: 0.9426\n",
      "Epoch 246/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 0.4576 - accuracy: 0.9426\n",
      "Epoch 247/500\n",
      "453/453 [==============================] - 0s 212us/sample - loss: 0.4535 - accuracy: 0.9426\n",
      "Epoch 248/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 0.4494 - accuracy: 0.9448\n",
      "Epoch 249/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.4456 - accuracy: 0.9470\n",
      "Epoch 250/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.4405 - accuracy: 0.9448\n",
      "Epoch 251/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.4374 - accuracy: 0.9448\n",
      "Epoch 252/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.4333 - accuracy: 0.9448\n",
      "Epoch 253/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.4315 - accuracy: 0.9470\n",
      "Epoch 254/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.4277 - accuracy: 0.9448\n",
      "Epoch 255/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 0.4238 - accuracy: 0.9448\n",
      "Epoch 256/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.4197 - accuracy: 0.9492\n",
      "Epoch 257/500\n",
      "453/453 [==============================] - 0s 219us/sample - loss: 0.4155 - accuracy: 0.9492\n",
      "Epoch 258/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 0.4145 - accuracy: 0.9448\n",
      "Epoch 259/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.4117 - accuracy: 0.9448\n",
      "Epoch 260/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 0.4157 - accuracy: 0.9426\n",
      "Epoch 261/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.4137 - accuracy: 0.9426\n",
      "Epoch 262/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 0.4185 - accuracy: 0.9426\n",
      "Epoch 263/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 0.4203 - accuracy: 0.9404\n",
      "Epoch 264/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 0.4075 - accuracy: 0.9404\n",
      "Epoch 265/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.4249 - accuracy: 0.9382\n",
      "Epoch 266/500\n",
      "453/453 [==============================] - 0s 288us/sample - loss: 0.4302 - accuracy: 0.9316\n",
      "Epoch 267/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.4176 - accuracy: 0.9382\n",
      "Epoch 268/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.4197 - accuracy: 0.9316\n",
      "Epoch 269/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.4192 - accuracy: 0.9360\n",
      "Epoch 270/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.5112 - accuracy: 0.9117\n",
      "Epoch 271/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.5299 - accuracy: 0.8918\n",
      "Epoch 272/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.5181 - accuracy: 0.9139\n",
      "Epoch 273/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 0.4728 - accuracy: 0.9249\n",
      "Epoch 274/500\n",
      "453/453 [==============================] - 0s 204us/sample - loss: 0.4481 - accuracy: 0.9294\n",
      "Epoch 275/500\n",
      "453/453 [==============================] - 0s 213us/sample - loss: 0.4279 - accuracy: 0.9316\n",
      "Epoch 276/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 0.4133 - accuracy: 0.9382\n",
      "Epoch 277/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.4034 - accuracy: 0.9404\n",
      "Epoch 278/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.3978 - accuracy: 0.9426\n",
      "Epoch 279/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 0.3770 - accuracy: 0.9448\n",
      "Epoch 280/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.3736 - accuracy: 0.9404\n",
      "Epoch 281/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 0.3662 - accuracy: 0.9404\n",
      "Epoch 282/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.3581 - accuracy: 0.9382\n",
      "Epoch 283/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.3546 - accuracy: 0.9426\n",
      "Epoch 284/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.3558 - accuracy: 0.9404\n",
      "Epoch 285/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.3469 - accuracy: 0.9448\n",
      "Epoch 286/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.3448 - accuracy: 0.9470\n",
      "Epoch 287/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 0.3700 - accuracy: 0.9404\n",
      "Epoch 288/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 0.3611 - accuracy: 0.9382\n",
      "Epoch 289/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.3456 - accuracy: 0.9426\n",
      "Epoch 290/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.3338 - accuracy: 0.9470\n",
      "Epoch 291/500\n",
      "453/453 [==============================] - 0s 197us/sample - loss: 0.3277 - accuracy: 0.9470\n",
      "Epoch 292/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.3248 - accuracy: 0.9470\n",
      "Epoch 293/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.3208 - accuracy: 0.9470\n",
      "Epoch 294/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 0.3186 - accuracy: 0.9470\n",
      "Epoch 295/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 0.3161 - accuracy: 0.9470\n",
      "Epoch 296/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.3132 - accuracy: 0.9470\n",
      "Epoch 297/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 0.3106 - accuracy: 0.9470\n",
      "Epoch 298/500\n",
      "453/453 [==============================] - 0s 198us/sample - loss: 0.3077 - accuracy: 0.9492\n",
      "Epoch 299/500\n",
      "453/453 [==============================] - 0s 204us/sample - loss: 0.3055 - accuracy: 0.9470\n",
      "Epoch 300/500\n",
      "453/453 [==============================] - 0s 300us/sample - loss: 0.3040 - accuracy: 0.9470\n",
      "Epoch 301/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 0.3016 - accuracy: 0.9470\n",
      "Epoch 302/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 0.2997 - accuracy: 0.9470\n",
      "Epoch 303/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.2966 - accuracy: 0.9470\n",
      "Epoch 304/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 0.2948 - accuracy: 0.9470\n",
      "Epoch 305/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.2926 - accuracy: 0.9448\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 235us/sample - loss: 0.2905 - accuracy: 0.9448\n",
      "Epoch 307/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 0.2890 - accuracy: 0.9470\n",
      "Epoch 308/500\n",
      "453/453 [==============================] - 0s 205us/sample - loss: 0.2874 - accuracy: 0.9470\n",
      "Epoch 309/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.2853 - accuracy: 0.9448\n",
      "Epoch 310/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.2834 - accuracy: 0.9470\n",
      "Epoch 311/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.2819 - accuracy: 0.9470\n",
      "Epoch 312/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.2802 - accuracy: 0.9470\n",
      "Epoch 313/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 0.2784 - accuracy: 0.9470\n",
      "Epoch 314/500\n",
      "453/453 [==============================] - 0s 282us/sample - loss: 0.2766 - accuracy: 0.9470\n",
      "Epoch 315/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 0.2745 - accuracy: 0.9470\n",
      "Epoch 316/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.2724 - accuracy: 0.9470\n",
      "Epoch 317/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.2716 - accuracy: 0.9448\n",
      "Epoch 318/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.2697 - accuracy: 0.9470\n",
      "Epoch 319/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.2745 - accuracy: 0.9426\n",
      "Epoch 320/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.2731 - accuracy: 0.9448\n",
      "Epoch 321/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.2704 - accuracy: 0.9448\n",
      "Epoch 322/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.2636 - accuracy: 0.9470\n",
      "Epoch 323/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 0.2631 - accuracy: 0.9470\n",
      "Epoch 324/500\n",
      "453/453 [==============================] - 0s 219us/sample - loss: 0.2599 - accuracy: 0.9448\n",
      "Epoch 325/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.2586 - accuracy: 0.9470\n",
      "Epoch 326/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 0.2564 - accuracy: 0.9470\n",
      "Epoch 327/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.2553 - accuracy: 0.9492\n",
      "Epoch 328/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.2533 - accuracy: 0.9470\n",
      "Epoch 329/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.2513 - accuracy: 0.9470\n",
      "Epoch 330/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.2508 - accuracy: 0.9448\n",
      "Epoch 331/500\n",
      "453/453 [==============================] - 0s 286us/sample - loss: 0.2493 - accuracy: 0.9448\n",
      "Epoch 332/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 0.2474 - accuracy: 0.9448\n",
      "Epoch 333/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.2457 - accuracy: 0.9448\n",
      "Epoch 334/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.2440 - accuracy: 0.9470\n",
      "Epoch 335/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.2434 - accuracy: 0.9470\n",
      "Epoch 336/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.2421 - accuracy: 0.9492\n",
      "Epoch 337/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.2403 - accuracy: 0.9470\n",
      "Epoch 338/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.2390 - accuracy: 0.9492\n",
      "Epoch 339/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.2377 - accuracy: 0.9470\n",
      "Epoch 340/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.2361 - accuracy: 0.9492\n",
      "Epoch 341/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.2350 - accuracy: 0.9492\n",
      "Epoch 342/500\n",
      "453/453 [==============================] - 0s 206us/sample - loss: 0.2343 - accuracy: 0.9448\n",
      "Epoch 343/500\n",
      "453/453 [==============================] - 0s 198us/sample - loss: 0.2328 - accuracy: 0.9470\n",
      "Epoch 344/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 0.2314 - accuracy: 0.9470\n",
      "Epoch 345/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 0.2302 - accuracy: 0.9448\n",
      "Epoch 346/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.2289 - accuracy: 0.9448\n",
      "Epoch 347/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.2278 - accuracy: 0.9492\n",
      "Epoch 348/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 0.2263 - accuracy: 0.9426\n",
      "Epoch 349/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 0.2249 - accuracy: 0.9470\n",
      "Epoch 350/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.2237 - accuracy: 0.9448\n",
      "Epoch 351/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.2226 - accuracy: 0.9448\n",
      "Epoch 352/500\n",
      "453/453 [==============================] - 0s 284us/sample - loss: 0.2217 - accuracy: 0.9448\n",
      "Epoch 353/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.2205 - accuracy: 0.9492\n",
      "Epoch 354/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.2186 - accuracy: 0.9470\n",
      "Epoch 355/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.2176 - accuracy: 0.9448\n",
      "Epoch 356/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.2166 - accuracy: 0.9426\n",
      "Epoch 357/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.2154 - accuracy: 0.9448\n",
      "Epoch 358/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.2144 - accuracy: 0.9470\n",
      "Epoch 359/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.2136 - accuracy: 0.9470\n",
      "Epoch 360/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.2125 - accuracy: 0.9470\n",
      "Epoch 361/500\n",
      "453/453 [==============================] - 0s 203us/sample - loss: 0.2116 - accuracy: 0.9426\n",
      "Epoch 362/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.2105 - accuracy: 0.9426\n",
      "Epoch 363/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 0.2099 - accuracy: 0.9470\n",
      "Epoch 364/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.2090 - accuracy: 0.9470\n",
      "Epoch 365/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.2078 - accuracy: 0.9426\n",
      "Epoch 366/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.2072 - accuracy: 0.9448\n",
      "Epoch 367/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.2067 - accuracy: 0.9470\n",
      "Epoch 368/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.2055 - accuracy: 0.9448\n",
      "Epoch 369/500\n",
      "453/453 [==============================] - 0s 219us/sample - loss: 0.2050 - accuracy: 0.9470\n",
      "Epoch 370/500\n",
      "453/453 [==============================] - 0s 277us/sample - loss: 0.2038 - accuracy: 0.9492\n",
      "Epoch 371/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.2028 - accuracy: 0.9514\n",
      "Epoch 372/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.2027 - accuracy: 0.9470\n",
      "Epoch 373/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.2011 - accuracy: 0.9492\n",
      "Epoch 374/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 0.2001 - accuracy: 0.9492\n",
      "Epoch 375/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.1988 - accuracy: 0.9448\n",
      "Epoch 376/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.1982 - accuracy: 0.9492\n",
      "Epoch 377/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.1971 - accuracy: 0.9492\n",
      "Epoch 378/500\n",
      "453/453 [==============================] - 0s 211us/sample - loss: 0.1967 - accuracy: 0.9470\n",
      "Epoch 379/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 0.1953 - accuracy: 0.9470\n",
      "Epoch 380/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.1944 - accuracy: 0.9470\n",
      "Epoch 381/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.1934 - accuracy: 0.9470\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 234us/sample - loss: 0.1926 - accuracy: 0.9470\n",
      "Epoch 383/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.1917 - accuracy: 0.9470\n",
      "Epoch 384/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.1911 - accuracy: 0.9448\n",
      "Epoch 385/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.1903 - accuracy: 0.9448\n",
      "Epoch 386/500\n",
      "453/453 [==============================] - 0s 212us/sample - loss: 0.1891 - accuracy: 0.9448\n",
      "Epoch 387/500\n",
      "453/453 [==============================] - 0s 277us/sample - loss: 0.1890 - accuracy: 0.9448\n",
      "Epoch 388/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.1883 - accuracy: 0.9470\n",
      "Epoch 389/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.1873 - accuracy: 0.9426\n",
      "Epoch 390/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.1863 - accuracy: 0.9470\n",
      "Epoch 391/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.1855 - accuracy: 0.9426\n",
      "Epoch 392/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.1844 - accuracy: 0.9448\n",
      "Epoch 393/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.1841 - accuracy: 0.9426\n",
      "Epoch 394/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 0.1841 - accuracy: 0.9448\n",
      "Epoch 395/500\n",
      "453/453 [==============================] - 0s 201us/sample - loss: 0.1832 - accuracy: 0.9426\n",
      "Epoch 396/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.1819 - accuracy: 0.9448\n",
      "Epoch 397/500\n",
      "453/453 [==============================] - 0s 191us/sample - loss: 0.1813 - accuracy: 0.9470\n",
      "Epoch 398/500\n",
      "453/453 [==============================] - 0s 210us/sample - loss: 0.1812 - accuracy: 0.9470\n",
      "Epoch 399/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.1796 - accuracy: 0.9470\n",
      "Epoch 400/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.1790 - accuracy: 0.9448\n",
      "Epoch 401/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 0.1780 - accuracy: 0.9426\n",
      "Epoch 402/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.1777 - accuracy: 0.9426\n",
      "Epoch 403/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.1782 - accuracy: 0.9426\n",
      "Epoch 404/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.1777 - accuracy: 0.9448\n",
      "Epoch 405/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.1770 - accuracy: 0.9448\n",
      "Epoch 406/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.1755 - accuracy: 0.9448\n",
      "Epoch 407/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.1745 - accuracy: 0.9426\n",
      "Epoch 408/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 0.1740 - accuracy: 0.9448\n",
      "Epoch 409/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.1731 - accuracy: 0.9470\n",
      "Epoch 410/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.1728 - accuracy: 0.9426\n",
      "Epoch 411/500\n",
      "453/453 [==============================] - 0s 199us/sample - loss: 0.1716 - accuracy: 0.9470\n",
      "Epoch 412/500\n",
      "453/453 [==============================] - 0s 195us/sample - loss: 0.1709 - accuracy: 0.9448\n",
      "Epoch 413/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.1703 - accuracy: 0.9404\n",
      "Epoch 414/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.1698 - accuracy: 0.9470\n",
      "Epoch 415/500\n",
      "453/453 [==============================] - 0s 265us/sample - loss: 0.1690 - accuracy: 0.9448\n",
      "Epoch 416/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.1684 - accuracy: 0.9470\n",
      "Epoch 417/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.1671 - accuracy: 0.9470\n",
      "Epoch 418/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.1671 - accuracy: 0.9448\n",
      "Epoch 419/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.1666 - accuracy: 0.9470\n",
      "Epoch 420/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.1663 - accuracy: 0.9448\n",
      "Epoch 421/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.1665 - accuracy: 0.9426\n",
      "Epoch 422/500\n",
      "453/453 [==============================] - 0s 201us/sample - loss: 0.1651 - accuracy: 0.9470\n",
      "Epoch 423/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 0.1646 - accuracy: 0.9492\n",
      "Epoch 424/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.1633 - accuracy: 0.9492\n",
      "Epoch 425/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.1637 - accuracy: 0.9470\n",
      "Epoch 426/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.1630 - accuracy: 0.9448\n",
      "Epoch 427/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 0.1627 - accuracy: 0.9448\n",
      "Epoch 428/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.1617 - accuracy: 0.9470\n",
      "Epoch 429/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.1610 - accuracy: 0.9448\n",
      "Epoch 430/500\n",
      "453/453 [==============================] - 0s 279us/sample - loss: 0.1601 - accuracy: 0.9470\n",
      "Epoch 431/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.1605 - accuracy: 0.9448\n",
      "Epoch 432/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.1597 - accuracy: 0.9470\n",
      "Epoch 433/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.1603 - accuracy: 0.9492\n",
      "Epoch 434/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 0.1756 - accuracy: 0.9426\n",
      "Epoch 435/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 0.2338 - accuracy: 0.9316\n",
      "Epoch 436/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.3339 - accuracy: 0.9007\n",
      "Epoch 437/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.3382 - accuracy: 0.9051\n",
      "Epoch 438/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.2745 - accuracy: 0.9095\n",
      "Epoch 439/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.2542 - accuracy: 0.9316\n",
      "Epoch 440/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 0.2605 - accuracy: 0.9338\n",
      "Epoch 441/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 0.2504 - accuracy: 0.9249\n",
      "Epoch 442/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.2192 - accuracy: 0.9426\n",
      "Epoch 443/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.2249 - accuracy: 0.9404\n",
      "Epoch 444/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.2077 - accuracy: 0.9426\n",
      "Epoch 445/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.1901 - accuracy: 0.9426\n",
      "Epoch 446/500\n",
      "453/453 [==============================] - 0s 283us/sample - loss: 0.1880 - accuracy: 0.9404\n",
      "Epoch 447/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 0.1915 - accuracy: 0.9426\n",
      "Epoch 448/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.1807 - accuracy: 0.9448\n",
      "Epoch 449/500\n",
      "453/453 [==============================] - 0s 227us/sample - loss: 0.1754 - accuracy: 0.9470\n",
      "Epoch 450/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.1670 - accuracy: 0.9514\n",
      "Epoch 451/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.1650 - accuracy: 0.9514\n",
      "Epoch 452/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 0.1641 - accuracy: 0.9492\n",
      "Epoch 453/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.1613 - accuracy: 0.9492\n",
      "Epoch 454/500\n",
      "453/453 [==============================] - 0s 202us/sample - loss: 0.1568 - accuracy: 0.9514\n",
      "Epoch 455/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.1575 - accuracy: 0.9470\n",
      "Epoch 456/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.1570 - accuracy: 0.9492\n",
      "Epoch 457/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.1555 - accuracy: 0.9492\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 208us/sample - loss: 0.1543 - accuracy: 0.9448\n",
      "Epoch 459/500\n",
      "453/453 [==============================] - 0s 209us/sample - loss: 0.1536 - accuracy: 0.9514\n",
      "Epoch 460/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 0.1531 - accuracy: 0.9492\n",
      "Epoch 461/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 0.1534 - accuracy: 0.9492\n",
      "Epoch 462/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 0.1511 - accuracy: 0.9492\n",
      "Epoch 463/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 0.1499 - accuracy: 0.9470\n",
      "Epoch 464/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.1498 - accuracy: 0.9514\n",
      "Epoch 465/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.1491 - accuracy: 0.9470\n",
      "Epoch 466/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 0.1481 - accuracy: 0.9470\n",
      "Epoch 467/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.1475 - accuracy: 0.9492\n",
      "Epoch 468/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 0.1470 - accuracy: 0.9492\n",
      "Epoch 469/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.1465 - accuracy: 0.9492\n",
      "Epoch 470/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.1465 - accuracy: 0.9492\n",
      "Epoch 471/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.1456 - accuracy: 0.9470\n",
      "Epoch 472/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 0.1449 - accuracy: 0.9536\n",
      "Epoch 473/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.1446 - accuracy: 0.9470\n",
      "Epoch 474/500\n",
      "453/453 [==============================] - 0s 231us/sample - loss: 0.1445 - accuracy: 0.9470\n",
      "Epoch 475/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.1443 - accuracy: 0.9470\n",
      "Epoch 476/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.1442 - accuracy: 0.9492\n",
      "Epoch 477/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 0.1429 - accuracy: 0.9470\n",
      "Epoch 478/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 0.1430 - accuracy: 0.9492\n",
      "Epoch 479/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 0.1426 - accuracy: 0.9448\n",
      "Epoch 480/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.1414 - accuracy: 0.9514\n",
      "Epoch 481/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 0.1414 - accuracy: 0.9514\n",
      "Epoch 482/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 0.1412 - accuracy: 0.9470\n",
      "Epoch 483/500\n",
      "453/453 [==============================] - 0s 286us/sample - loss: 0.1408 - accuracy: 0.9492\n",
      "Epoch 484/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.1392 - accuracy: 0.9514\n",
      "Epoch 485/500\n",
      "453/453 [==============================] - 0s 225us/sample - loss: 0.1400 - accuracy: 0.9514\n",
      "Epoch 486/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 0.1390 - accuracy: 0.9492\n",
      "Epoch 487/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.1390 - accuracy: 0.9470\n",
      "Epoch 488/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.1387 - accuracy: 0.9492\n",
      "Epoch 489/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.1379 - accuracy: 0.9514\n",
      "Epoch 490/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.1375 - accuracy: 0.9492\n",
      "Epoch 491/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.1373 - accuracy: 0.9514\n",
      "Epoch 492/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.1369 - accuracy: 0.9470\n",
      "Epoch 493/500\n",
      "453/453 [==============================] - 0s 200us/sample - loss: 0.1363 - accuracy: 0.9492\n",
      "Epoch 494/500\n",
      "453/453 [==============================] - 0s 206us/sample - loss: 0.1355 - accuracy: 0.9470\n",
      "Epoch 495/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 0.1357 - accuracy: 0.9470\n",
      "Epoch 496/500\n",
      "453/453 [==============================] - 0s 220us/sample - loss: 0.1355 - accuracy: 0.9470\n",
      "Epoch 497/500\n",
      "453/453 [==============================] - 0s 205us/sample - loss: 0.1346 - accuracy: 0.9492\n",
      "Epoch 498/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 0.1344 - accuracy: 0.9514\n",
      "Epoch 499/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.1335 - accuracy: 0.9470\n",
      "Epoch 500/500\n",
      "453/453 [==============================] - 0s 222us/sample - loss: 0.1336 - accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "  model = Sequential()\n",
    "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "  model.add(Bidirectional(LSTM(20)))\n",
    "  model.add(Dense(total_words, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  history = model.fit(xs, ys, epochs=500, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YXGelKThoTT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.style.use('seaborn')\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "poeprYK8h-c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Vc6PHgxa6Hm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laurence went to dublin i soon terrible hullabaloo old rose hall hall hearty hearty hall mavrone mavrone mavrone me me i ground ground at i suppose suppose suppose father hall hall mavrone mavrone mavrone mavrone mavrone me me me me i i i might much as water suppose father hall hall entangled mavrone mavrone how me squeezed up me ground i suppose suppose suppose suppose water suppose father rose hall hall mavrone mavrone mavrone mavrone me me me me i i i might much as water suppose father hall hall entangled mavrone mavrone how me squeezed up me ground i suppose suppose suppose suppose\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Course 3 - Week 4 - Lesson 1 - Notebook.ipynb",
   "provenance": [
    {
     "file_id": "1V60jn23JMcMpwhF-KvCTYIIfm4J2X6v5",
     "timestamp": 1558707866173
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
